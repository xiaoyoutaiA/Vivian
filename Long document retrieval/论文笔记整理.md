## 论文笔记整理

### 一、文档检索论文概括

1. {**Adaptive Document Retrieval for Deep Question Answering**,`EMNLP2018`} 

   本文主要研究数据集的大小对文档检索结果的影响，基于此提出了一种自适应的文档缩减模型，它可以根据问题和数据集(语料库)的大小自动调整文档检索的数量。自适应方法的目的是寻找到一个合适的n，其中n∈(1,t)。当给定t个文档，我们可以使用TF-IDF或者更复杂的概率模型对文档进行打分，根据计算的分数来确定检索的文档数量。

   

2. {**Ad-hoc Document Retrieval using Weak-Supervision with BERT and GPT2**,`ACL2019`}

    本文提出利用bert和gpt2做文档检索，我们假设文档至少有三个字段标题、摘要和内容。当文档缺少标题时，我们将其第一个句子视为其增强标题(监督信号),然后用bert-q(query)-t(title)检索。类似地，每当文档缺少摘要时，我们将其内容的前512个单词视为摘要(监督信号)，然后用bert-q-a(abstract)检索。最后通过两步PoolRank无监督融合方法，将两个弱监督的微调BERT模型与基线IR方法相结合。

   

3. {**Applying BERT to Document Retrieval with Birch**, `ACL2019`} 

   将birch社区的Anserini信息检索工具toolkit与基于BERT的文档排名模型集成在一起，该模型提供了端到端的开源搜索引擎(给定一个查询Q，通过python接口将其传给Anserini，利用其强大的检索能力筛选出top-k个文档，然后用bert模型对其精读并排序)。

   

4. {**Biomedical Document Retrieval for Clinical Decision Support System**,`ACL2018`} 

   由于医学术语的复杂性、模糊性及其专用缩和较长的实体，使其难以识别和检索，本文提出利用查询扩展的方式(即：通过使用额外的相关词汇扩展查询，并重新对所有查询词进行加权)克服词汇表不匹配的问题。

   

5. {**Conformer-kernel with query term independence for document retrieval**,`arxiv2020`} 

   传统的Transformer-Kernel(TK)输入序列的长度受自注意力的限制，我们在此基础上提出了CK模型，首先，我们优化了查询器编码去掉了查询编码器的transformer层，导出查询和文档术语的上下文向量表示。然后，基于上下文项嵌入TK创建交互矩阵X，分别计算每个交互矩阵的分数，最后通过聚合函数以生成最终的查询文档分数。

   

6. {**Cross-Lingual Document Retrieval with Smooth Learning**,`ACL2020`} 

   

7. {**Cross-Domain Modeling of Sentence-Level Evidencefor Document Retrieval**,`IJCNLP2019`}

    本文研究将bert应用于新闻文章这一类特别的文档检索和检索模型的跨域。我们模型的核心是Bert句子级相关性分类器。我们通过将查询Q和句子S连接成序列[[CLS]，Q，[Sep]，S，[Sep]]并将小批量中的每个序列填充到批量中的最大长度来形成Bert的输入。我们将对应于模型中[CLS]标记的最终隐藏状态提供给单层神经网络，其输出表示句子S与查询Q相关的概率。

   

8. {**Doc2hash: Learning Discrete Latent variables for Documents Retrieval**,`NAACL2019`} 

   在本文中，我们提出了一种方法Doc2hash应用于文档检索。哈希是一种快速的相似度搜索解决方案，在文档检索中，语义哈希是将文档转换为捕获语义信息的二进制码(哈希码)的策略。通过计算哈希码之间hamming distance的距离，可以使用查询来检索类似的文档。

   

9. {**How Can Graph Neural Networks Help Document Retrieval: A Case Study on CORD19 with Concept Map Generation**,`ECIR2022`} 

   本文研究了图神经网络如何帮助文档检索。首先，我们通过概念图的方式将文本建模为一个以单词/短语为顶点、以它们之间的关系为边的图形。然后，将GNN应用于每个单独的概念图通过邻域变换和聚合的方式更新图，最后，计算图的相关性得分用于文档排序。

   

10. {**Integrating Semantics and Neighborhood Information with Graph-Driven Generative Models for Document Retrieval**,`ACL2021`} 

    在本文中我们尝试将将语义和邻域信息与图驱动生成模型集成到文档检索中。具体来说，我们首先用多元高斯分布对邻域信息进行编码。利用这种高斯分布作为生成模型的先验，邻域信息可以自然地融入到基于语义的哈希模型中。

    

11. {**Interpretable & Time-Budget-Constrained Contextualization for Re-Ranking**, `ECAI2020`} 

    re-rank模型比较方法：在相同的时间内，更快的重排序模型可以比效率较低的模型包含更多的文档，从而提高效率。基于此我们提出了TK一种用于临时检索的可解释的神经重排序模型，首先我们分别对查询和文档序列进行上下文分析，然后利用成对余弦相似性创建交互匹配矩阵，之后对文档维度进行求和，并通过对数和文档长度对每个查询词特征进行规范化，最后将对数和长度标准化分数与单个前馈（FF）层相结合，形成最终结果分数。

    

12. {**Improving BERT-based Query-by-Document Retrieval with Multi-Task Optimization**,`ECIR2022`} 

    按文档查询（QBD，Query-by-document ）检索是一项信息检索任务，其中种子文档充当查询，目标是检索相关文档。在这项工作中，我们改进了BERT-re-ranker在其[CLS]标记最终隐藏状态的顶部加上一个投影层，结合MLM和NP(下一句预测)优化文档结构信息，最后利用bert其计算查询和文档的相关性得分。

13. {**Improving Low-Resource Cross-lingual Document Retrieval by Reranking with Deep Bilingual Representations**,`ACL2019`}

     本文提出利用深度双语查询文档表示来提高低资源跨语言文档检索性能的构思。给定源语言Q的用户查询和目标语言D的文档，系统计算一个相关分数s(Q, D)。我们的模型首先将文档转换为ˆD，或将查询转换为ˆQ，然后使用四个独立的组件进行匹配:(1)源查询与目标文档匹配，(2)源查询与源文档匹配，(3)目标查询与源文档匹配，(4)目标查询与目标文档匹配。最终的相关性分数的计算包含了所有部分:s(Q, D) = s(Q, D) + s(Q,ˆD) + s(ˆQ,ˆD) + s(ˆQ, D)

    

14. {**Keyphrase Generation for Scientific Document Retrieval**,`ACL2020`} 

    本文研究了关键字或关键词短语的生成是否有利于科学文档检索。文章利用seq2seq模型对文档进行训练生成关键词，同时结合文档的数据结构，这里要求必须是带有标题、摘要或者作者名字的科学文档，通过传统的术语匹配技术进行文档检索。

    

15. {**Keyword Extraction for Improved Document Retrieval in Conversational Search**,`arxiv2021`}

     本文主要研究从人机交互中检索到的关键词的识别是否有助于获得更好的检索结果。具体流程： 在对话阶段（系统与用户交互以澄清查询歧义）之后，对话序列被传递给关键字提取器(seq-to-seq/bert)，从句子中识别最重要的术语。与此同时，文档检索模型根据原始对话对文档进行第一次相关性排序。最后，神经IR模型使用来自IR阶段的top-k文档和关键字提取器从关键字提取阶段获得的关键字作为系统的输入，执行重新排序(drmm/dssm IR模型)。

    

16. {**Leveraging Semantic and Lexical Matching to Improve the Recall of Document Retrieval Systems: A Hybrid Approach**,`arxiv2020`}  

    本文提出了一种混合检索方法，该方法利用语义(基于深度神经网络)和词汇(基于关键字匹配)检索模型。与重排序相比： 本工作的重点是检索阶段，其主要目标是最大限度地召回被检索的相关文档。这与重排序的目的不同，重排序的目的是优化最终列表的高排名精度。此外，由于检索阶段是针对集合中的所有文档执行的，因此模型的一个主要需求是高效。

    

17. {**PARM: A Paragraph Aggregation Retrieval Model for Dense Document-to-Document Retrieval**,`ECIR2022`}

     我们提出了一种段落聚合检索模型（PARM），它将DPR模型从有限的输入长度中解放出来。采用的模型检索方法：PARM在段落级别检索文档：对于每个查询段落，根据其段落检索相关文档。然后将每个查询段落的相关结果聚合到整个查询文档的一个排序列表中。采用的聚合方法：我们提出了基于向量的倒数秩融合加权聚合（VRRF），优化了查询和文档表示。最后，我们使用查询ˆq和候选文档ˆd的聚合嵌入之间的点积计算查询和候选文档之间的相关性得分。

    

18. {**Reading Wikipedia to Answer Open-Domain Questions**,`ACL2017`} 

    本文的架构十分清晰，DrQA主要包含两个部分，一部分是文献检索，这个部分主要是从wiki中抽取和问题最匹配的top-k个文档，另一部分是一个阅读理解的神经网络架构，主要完成任务是在给定的top-k个文档中找到问题的答案。

    

19. {**Simple Applications of BERT for Ad Hoc Document Retrieval**,`arxiv2019`} 

    鉴于将bert应用于qa的成功，本文尝试将bert应用于文档检索。与BERTserini一样首先使用Anserini IRtoolkit进行初始检索，然后将检索后的文档输入到BERT分类器，通过线性差值将BERT评分和检索评分相结合。

    

20. {**Simplified TinyBERT: Knowledge Distillation for Document Retrieval**,`ECIR2021`} 

    在本文中，我们研究了TinyBERT模型两种蒸馏方法对文档排序任务的有效性。具体步骤如下:1、使用 Bert 作为 teacher 模型，而且不对其进行微调，利用大规模本语料库作为学习数据，这样做的好处是相当于获得一个通用的 TinyBert。2、然后使用微调后的 Bert 作为 teacher 模型，针对特定的任务，再进行一次蒸馏，得到最终的 TinyBert。也就是相当于把第一步当作一个 TinyBert 的初始化操作。

    

21. {**STRUCTURE WITH SEMANTICS: EXPLOITING DOCUMENT RELATIONS FOR RETRIEVAL**,} 

    本文提出了一种通过集成文档内容和文档间关系来学习文档表示的整体方法。同时通过度量学习分析了关系网络中复杂的邻域结构，以便有效地对相似/不相似的文档对进行采样，并定义了一个新的五重损失函数，鼓励语义相关的文档对在表示空间中更近，而结构无关的文档对在表示空间中相隔很远。

    

22. {**Augmenting Document Representations for Dense Retrieval with Interpolation and Perturbation**,} 

    密集的模型需要大量标注的训练数据来获得显著的性能，而获取由人类标注的查询文档对往往是一个挑战。基于此我们提出了一种简单而有效的针对密集检索(DAR)框架的文档扩充方法，该方法通过对文档的插值和扰动来扩充文档的表示。

    

23. {**Dense Hierarchical Retrieval for Open-Domain Question Answering**,`emnlp2021`} 

    密集神经网络文本检索的检索器高度依赖于文档的拆分过程，在本研究中，我们提出了一种分层检索框架(DHR)它由一个密集的文档级检索器(DHR-D)和一个密集的段落级检索器(DHR-P)组成。文档级检索器的目标是捕获文档的粗粒度语义，即问题的嵌入与其相关文档呈正相关关系。文档级检索器的目标是删除与答案无关的文档并返回相关的文档，然后将这些文档作为一个精细化的语料库提供给段落级检索器。当相关文献由相似主题的段落组成时，段落级检索器倾向于识别关键证据，这可能有助于正确回答。

    

24. {**Improving Document Representations by Generating Pseudo Query Embeddings for Dense Retrieval**,`ACL2021`} 

     传统的密集检索模型的基本结构大多是双编码器。但是，由于查询是不可知的，这种简单的结构可能会在文档编码期间导致严重的信息丢失。基于此本文提出通过迭代聚类过程来模拟对每个文档的查询，并通过多个伪查询来表示文档，然后利用伪查询计算相关性得分。

    

25. {**Multi-Task Retrieval for Knowledge-Intensive Tasks**,`ACL2021`} 多任务的

    

26. {**Progressively Optimized Bi-Granular Document Representation for Scalable Embedding Based Retrieval**,`WWW2022`} 

    本文主要解决的是query-document检索中的性能问题。目前业内的主流检索方法是query侧和document侧分别使用encoder生成表示，在线阶段使用ANN的方式进行向量检索。当document的数量较大时，直接放到内存中检索是不现实的。因此，一般会通过一些优化的检索方法，例如基于量化的检索方法进行高效检索。将每个document生成两个embedding，一个是通过量化生成的离散表示sparse embedding，这部分表示的数据量较小，可以直接放到内存中，主要用来进行粗选，在全量corpus中选出最相关的top-K；另一部分是dense embedding，会在粗选的候选集基础上进行进一步筛选，得到最终的结果。

    

27. {**Semi-Siamese Bi-encoder Neural Ranking Model Using Lightweight Fine-Tuning**,`WWW2022`} 

    在query-document检索问题中，基于预训练Bert作为Encoder的方式有两种bi-encoder和cross-encoder。在这项工作中，我们展示了两种提高基于bert的双编码器性能的方法。第一种是第一种方法是用一个轻量级的微调来替换完整的微调步骤（如LoRA、prefix finetune）。第二种方法是开发半暹罗模型。首先使用预训练的Bert初始化query侧和document侧的Encoder，并结合Semi-Siamese半孪生网络改造prefix finetune和LoRA两种轻量级finetune既保证两个Encoder的共性，又能建立差异性。

    

28. {**ED2LM: Encoder-Decoder to Language Model for Faster Document Re-ranking Inference**,`ACL2022`} 

    传统的仅编码器(如BERT)范式或编码器-解码器(如T5)方法，对文档查询对进行重新排序，需要在推理时计算所有查询-文档对这会导致巨大的计算成本。本文提出了一种新的重新排序的训练和推理范式ED2LM，它由两部分构成Encoder和Decoder。首先将文档的单词划分然后送入到transformer层中进行编码，获取文档的最终表示。然后，将编码器的输出作为样本送入到解码器中，解码器在推理过程中生成文档的查询并将其与原查询做比较，如果一直则在查询后面的tag赋值为true,否则赋值为false。最后，通过解码查询和关注文档表示来产生排名分数。

    

29. {**A Graph-based Relevance Matching Model for Ad-hoc Retrieval**,`AAAI2021`} 

    在本研究中，我们提出了一个基于图的相关性匹配模型(GRMM)来解决远程项的匹配问题(使得模型可以在不同的数据集上进行检索任务)。对于一对查询和文档，我们首先将文档转换为单词图形式，其中节点特征是单词和每个查询术语之间的相似性。然后，利用图神经网络在文档图上传播这些匹配的信号。最后，为了估计相关性得分，我们对每个查询项采用k-max池化策略来过滤出不相关的噪声信息，并将其特征输入一个密集的神经层计算相关性得分。

    

30. {**B-PROP: Bootstrapped Pre-training with Representative Words Prediction for Ad-hoc Retrieval**,`SIGIR2021`} 

    最新为信息检索(IR)定制的预训练方法是PROP方法，但其性能受到ROP任务的限制(ROP预训练任务的核心是从文档中抽取具有代表性的单词集)。基于此本文提出了一种基于BERT的预训练方法(即B-PROP)用于特别检索,同时引入了一种新的对比方法，利用BERT的自我注意机制从文档中抽取具有代表性的单词。首先bert的抽取更具有代表性，但是容易抽取不必要的词如in,of等等，改进方法是用bert来抽取用ROP来预测。然后根据上一步抽取的词集基础上再用ROP抽取重要的词集，之后用MLM提取feature，最后使用BERT计算相关性得分。

    

31. {**PROP: Pre-training with Representative Words Prediction for Ad-hoc Retrieval**,`WSDM2021`} 

    在本文中，我们提出了用具有代表性的words预测(PROP)进行预训练的特别检索。给定一个输入文档，我们根据文档语言模型对一对单词集进行采样，每个采样的单词集都可以看作是从文档中生成的伪查询,这样，具有更高可能性的单词集就被认为是对文档更具有“代表性”的查询。然后，我们对transformer模型进行预训练，以预测两个词集之间的成对偏好，以及掩码语言模型(MLM)目标(两者的作用是提取feature)将伪查询补充完整用于检索。

    

32. {**Multi-View Document Representation Learning for Open-Domain Dense Retrieval**,`ACL2022`}

    本文提出了一种方法MVR，使用多个embedding来表示一个文档，同时采取了一系列措施使得这些embedding不会丢失信息。第一步：首先是基于普通Bi-encoder的改进，将文档和查询分别输入给模型，得到各自的embedding，然后使用余弦相似度或欧式距离计算查询和文档的相似程度，之后使用对比学习的方法构造损失函数拉进查询和正相关文档之间的距离。第二步：结合Multi-viewer的思想通过其构建更细粒度的语义单元使用特殊字符[VIE]对查询和文档进行构造，并选取得分最大的查询文档对。第三步：构造新的损失函数将全局和局部损失相结合，全局的损失为了提升模型的精度，局部的损失为了防止模型退化。

    

### 二、文档检索使用的数据集

| dataset |                        |                   |              |                    |        |        |         |
| ------- | ---------------------- | ----------------- | ------------ | ------------------ | ------ | ------ | ------- |
| [1]     | SQuAD1.1               | TREC2015          | WebQuestions | WikiMovies         |        |        |         |
| [2]     | TREC-COVID             | WSJ               | AP           |                    |        |        |         |
| [3]     | Robust04               |                   |              |                    |        |        |         |
| [4]     | CDS 2014               | CDS 2015          | CDS 2016     |                    |        |        |         |
| [5]     | TREC2019               |                   |              |                    |        |        |         |
| [6]     | CLIR                   |                   |              |                    |        |        |         |
| [7]     | Robust04               | Core17            | Core18       |                    |        |        |         |
| [8]     | Reuters                | TMC               | RCV1         |                    |        |        |         |
| [9]     | TREC-COVID             |                   |              |                    |        |        |         |
| [10]    | Reuters                | TMC               | 20Newsgroups |                    |        |        |         |
| [11]    | MS-Passage             | MS-Document       | TREC CAR     |                    |        |        |         |
| [12]    | Caleee 2021            |                   |              |                    |        |        |         |
| [13]    | CLIR                   |                   |              |                    |        |        |         |
| [14]    | NTCIR-2                |                   |              |                    |        |        |         |
| [15]    |                        |                   |              |                    |        |        |         |
| [16]    | TREC2019               |                   |              |                    |        |        |         |
| [17]    | COLIEE                 |                   |              |                    |        |        |         |
| [18]    | SQuAD                  | TREC2015          | WebQuestions | WikiMovies         |        |        |         |
| [19]    | Robust04               | TREC Microblog    |              |                    |        |        |         |
| [20]    | MS-Document            | TREC2019          |              |                    |        |        |         |
| [21]    | SciDocs                | arXivCS           | ACL-ARC      |                    |        |        |         |
| [22]    | open-domain QA         | TriviaQA(TQA)     |              |                    |        |        |         |
| [23]    | Natural Questions (NQ) | TriviaQA          | WebQuestions | CuratedTREC (TREC) |        |        |         |
| [24]    | MS MARCO               | OpenQA            |              |                    |        |        |         |
| [25]    | KILT                   | NQ                | TQA          | HoPo               |        |        |         |
| [26]    | TREC 2019              |                   |              |                    |        |        |         |
| [27]    | Robust04               | ClueWeb09b        | MS MARCO     |                    |        |        |         |
| [28]    | MS MARCO passage       | TREC 2019         |              |                    |        |        |         |
| [29]    | Robust04               | ClueWeb09-B       |              |                    |        |        |         |
| [30]    | Robust04               | ClueWeb09-B       | Gov2         | MQ2007             | MQ2008 | TRECDL | MSMARCO |
| [31]    | English Wikipedia      | MS MARCO Document | Robust04     | ClueWeb09-B        | Gov2   | MQ2007 | MQ2008  |
| [32]    | SQuAD                  | NQ                | TQA          |                    |        |        |         |

### 三、长文档检索论文概括

1. {**Long Document Ranking with Query-Directed Sparse Transformer**,`findings2020`} 

   在文档排序任务中，Transformer自注意力机制的计算成本与文档的长度有关，在本文中我们构建了QDS-Transformer模型，首先查询导向的稀疏注意通过控制窗口w的大小获取文档的局部表示，然后查询导向的全局注意结合在句子前添加特殊标记[sos]使用词-句-文档的层次结构获取文档的全局表示。最后结合局部和全局表示用于长文档检索。

   

2. {**Local self-attention over long text for efficient document retrieval**,`SIGIR2020`}

   本文提出了一个局部自注意机制，它考虑了文档术语上的一个移动窗口，并且每个术语只关注同一窗口中的其他术语。在整个文档中，这种局部注意力只占注意力的计算和内存成本的一小部分。窗口化方法还可以更紧凑地将填充文档打包成小批量，从而节省更多成本。我们还使用一个学习的饱和函数和两阶段池策略来识别文档的相关区域。

   

3. {**KeyBLD: Selecting Key Blocks with Local Pre-ranking for Long Document Information Retrieval**,`SIGIR2021`}

   本文提出一种新的解决BERT处理长文档的方法，筛选长文档的关键块拼凑成短文档。首先是关键块的分割，根据标点符号的强弱（如.和!）把长文档分割成块，且每个块不超过63个标记。然后每个关键块都由TF-IDF/BM25进行打分。最后将最相关的块连接在一起(按照它们在文档中出现的顺序)，并与查询一起形成BERT的输入。所选块的数量n取决于BERT的容量。

   

4. {**ERNIE-DOC: A Retrospective Long-Document Modeling Transformer**,`ACL2021`}

   本文中提出了一个ERNIE-DOC模型，这是一种基于递归变换的文档级语言预训练模型。本模型用了两种技术：即回顾性反馈机制(先粗读再精读)和增强的重复性机制，使ERNIE-DOC具有更长的有效上下文长度，能够捕获完整文档的上下文信息。

   

5. {**RLTM: An Efficient Neural IR Framework for Long Documents**,`IJCAI2019`}

   本文提出了一种新的端到端神经网络排序框架，称为增强长文本匹配（RLTM），首先，我们通过一个粗略选择模型从长文档中选择相关句子。其次，我们根据所选择的句子结合复杂的匹配模型生成相关性得分。 同时本文还引入了强化学习的方法让句子选择模型为句子匹配模型提供更优质的句子，以区分正面和负面文档。

   

6. {**Long Document Re-ranking with Modular Re-ranker**,`SIGIR2022`}

   在本文中，我们利用注意力机制和模块化Transformer re-ranker框架，对完整的查询到文档交互进行建模。首先，使用编码器模块对文档块进行独立编码。然后，一个交互模块对查询进行编码，并对所有文档块表示进行联合关注用于长文档重排序。

   

7. {**Socialformer: Social Network Inspired Long Document Modeling for Document Ranking**,`WWW2022`}

   在本文中，我们提出了socialformer模型，该模型将社交网络的特点引入到设计稀疏注意模式中，用于文档排序中的长文档建模。模型整体由四个步骤组成。首先，根据社交网络的特点，我们设计了四种稀疏注意模式，用概率抽样构建了一个图(静态距离/中心性，动态距离/中心性)。其次，我们提出了两种基于朋友圈的图划分策略(节点/边划分图)，以减少内存和计算复杂度。第三，我们设计了一个两阶段的信息传输模型(圈内/圈间交互)，以捕获更多的文档信息。最后，通过聚合段落和子图的表示，形成用于文档排序的综合文档表示。

   

8. {**Distant Supervision in BERT-based Adhoc Document Retrieval**,`CIKM2020`}

   本文提出了一个基于弱监督的转移段落标记方案，该方案有助于提高性能并从未标记的文档中收集相关段落。段落生成： 我们预先准备好了文档文本的标题。我们把每个文档分成长度为100的段落。段落相关性判断：1.QA DocRank没有将文档标签转移到段落，而是通过高质量模型来识别相关文档的相关段落。并且只考虑具有相关性得分为>𝜃1的段落，以此来获得查询-文档对的标签。最后，将该模型应用于测试集上，预测查询-段落对的相关性标签，并对这些分数进行聚合，得到相应的查询-文档的最终分数。我们采用四种聚合方法：FirstP，MaxP,SumP,AvgP 。2.QA Full DocRank我们为已标记和未标记文档的段落设置了两个不同的阈值（𝜃1，𝜃2）根据阈值来确定标签。

   

9. {**Big Bird: Transformers for Longer Sequences**,`NeurIPS2020`}

   谷歌最近又推出了一个重磅的稀疏注意力模型：Big Bird。之前各种刷榜的BERT和它的各种衍生版本RoBERTa等，都是构建在Transformer基础上。

   这些模型的核心竞争力就是全注意力机制，但这种机制会产生序列长度的二次依赖，如果输入的token过长，会撑爆内存，而长文本摘要等任务中，BERT的512token，就显得有点捉襟见肘。Big Bird相对于传统的全注意力机制来说变的更稀疏(将随机，局部和全局注意力相结合使得更稀疏)，作为更长序列上的Transformer，Big Bird不仅能注意到更长的上下文信息，还将计算的二次依赖降低到了线性。

### 四、长文档检索使用的数据集

| dataset |                   |               |                   |
| ------- | ----------------- | ------------- | ----------------- |
| [1]     | TREC 2019 DL      |               |                   |
| [2]     | TREC 2019 DL      |               |                   |
| [3]     | Robust04          | GOV2          |                   |
| [4]     | Human Label       | Click-Through |                   |
| [5]     | clueweb09         |               |                   |
| [6]     | Robust04          | clueweb09     | MS MARCO Document |
| [7]     | MS MARCO Document | TREC 2019 DL  |                   |
| [8]     | MS Marco          | TREC          |                   |
| [9]     | NQ                | TQA           | WikiHop           |
